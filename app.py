# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g8Vj4mO8YVBCa0VBX8ipUDkynGKWEtq5
"""

from google.colab import drive
drive.mount('/content/drive')

dataset_path = '/content/drive/MyDrive/G3CNN1/dataset'  # Update this to your dataset folder

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
import os

# Data generators for training and validation
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # EfficientNet preprocessing
    validation_split=0.2,                     # 20% validation split
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# Training generator
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),  # Resize images to 224x224 for EfficientNet
    batch_size=32,
    class_mode='binary',     # Binary classification
    subset='training'        # Use the training subset
)

# Validation generator
val_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation'      # Use the validation subset
)

# Load EfficientNetB0 base model
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
base_model.trainable = False

# Add custom classification layers
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print model summary
model.summary()

# Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,  # Adjust based on dataset size and performance
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_steps=val_generator.samples // val_generator.batch_size
)

# Evaluate the model
val_loss, val_acc = model.evaluate(val_generator)
print(f"Validation Accuracy: {val_acc:.2f}")

# Save the model
model.save('/content/drive/MyDrive/efficientnetb0_iris_tumor_classifier.h5')
print("Model saved to Google Drive.")

from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

def predict_image(img_path, model):
    # Load and preprocess the image
    image = load_img(img_path, target_size=(224, 224))
    image_array = img_to_array(image)
    image_array = preprocess_input(image_array)  # Preprocess for EfficientNet
    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension

    # Predict
    prediction = model.predict(image_array)[0][0]
    return "Tumor" if prediction > 0.5 else "Non-Tumor"

# Load the saved model
saved_model = tf.keras.models.load_model('/content/drive/MyDrive/efficientnetb0_iris_tumor_classifier.h5')

# Example prediction
test_image_path = '/content/drive/MyDrive/004_06_L.bmp'  # Update with your test image path
print("Prediction:", predict_image(test_image_path, saved_model))

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Define paths
base_dir = "/content/drive/MyDrive/G3CNN1/dataset"  # Replace with your folder path
tumor_dir = os.path.join(base_dir, "tumor")
non_tumor_dir = os.path.join(base_dir, "no_tumor")

# Image parameters
IMG_SIZE = (224, 224)  # Input size for VGG16
BATCH_SIZE = 32

# Data generators for loading and augmenting images
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 80-20 train-validation split
)

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

# Load VGG16 model without the top layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification layers
x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)  # Binary classification

# Create the model
model = Model(inputs=base_model.input, outputs=output)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
EPOCHS = 10
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS
)

# Save the trained model
model.save('/content/drive/MyDrive/tumor_vgg16_model.h5')

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f"Validation Accuracy: {accuracy:.2f}")

# Function to predict on new images
def predict_image(image_path):
    from tensorflow.keras.preprocessing.image import load_img, img_to_array

    img = load_img(image_path, target_size=IMG_SIZE)
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    prediction = model.predict(img_array)
    if prediction[0][0] > 0.5:
        print(f"Tumor detected with probability: {prediction[0][0]:.2f}")
    else:
        print(f"No tumor detected with probability: {1 - prediction[0][0]:.2f}")

# Example usage
test_image = "/content/drive/MyDrive/001_06_L.bmp"  # Replace with your test image
predict_image(test_image)

# Import necessary libraries
import gradio as gr
import numpy as np
import matplotlib.pyplot as plt

# Define a function to classify the image
def classify_image(image):
    # Dummy model prediction: replace with actual model
    # For demonstration, we randomly decide if a tumor is detected
    if np.random.rand() > 0.5:
        prediction = "Tumor Detected"
        probability = np.random.rand()
    else:
        prediction = "No Tumor"
        probability = 1 - np.random.rand()

    # Return the prediction and probability
    return f"{prediction} (Probability: {probability:.2f})"

# Create a Gradio interface
demo = gr.Interface(
    fn=classify_image,  # Function to classify the image
    inputs=gr.Image(type="numpy"),  # Input component for image upload
    outputs=gr.Textbox(label="Prediction"),  # Output component for prediction
    title="Tumor Detection",
    description="Upload an image to detect the presence of a tumor. The model will analyze the image and classify it as either 'Tumor Detected' or 'No Tumor', along with the probability of the prediction."
)

# Launch the interface
if __name__ == "__main__":
    demo.launch(show_error=True)

